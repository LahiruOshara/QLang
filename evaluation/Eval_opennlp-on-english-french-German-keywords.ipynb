{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/qald-8-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna(subset=['questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(df['questions'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "X = tfidf_transformer.fit_transform(X_train)\n",
    "\n",
    "# get feature names\n",
    "feature_names=vectorizer.get_feature_names()\n",
    "\n",
    "#Function for sorting tf_idf in descending order\n",
    "from scipy.sparse import coo_matrix\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "def ExtractKeyWords(text):\n",
    "    #generate tf-idf for the given text\n",
    "    tf_idf_vector=tfidf_transformer.transform(text)\n",
    "    \n",
    "    \n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "    #extract only the top n; n here is 3\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,3)\n",
    " \n",
    "    # now print the results\n",
    "    sentence = \"\"\n",
    "    for k in keywords:\n",
    "        sentence+=(\" \"+k)\n",
    "    return sentence\n",
    "\n",
    "new_set = []\n",
    "for text in X:\n",
    "    new_set.append(ExtractKeyWords(text))\n",
    "    \n",
    "df[\"questions\"]=new_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df[\"lang\"]=='en']\n",
    "df_fr = df[df[\"lang\"]=='fr']\n",
    "df_de = df[df[\"lang\"]=='de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLan(f,n):\n",
    "    result=[]\n",
    "    count=0\n",
    "    while count < n:\n",
    "        line = f.readline()\n",
    "        if line == \"\\n\":\n",
    "            continue\n",
    "        result.append(line[:3])\n",
    "        count+=1\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_opennlp(data):\n",
    "    with open('opennlp_input.txt', 'w') as f:\n",
    "        for q in data[\"questions\"]:\n",
    "            f.write(q+\"\\n\\n\")\n",
    "    os.system(\"/home/oshara/GSoC/DBPedia/openNLP/apache-opennlp-1.9.2/bin/opennlp LanguageDetector /home/oshara/GSoC/DBPedia/openNLP/langdetect-183.bin </home/oshara/GSoC/DBPedia/QLang/evaluation/opennlp_input.txt> /home/oshara/GSoC/DBPedia/QLang/evaluation/opennlp_output.txt\")\n",
    "    n=len(data)\n",
    "    with open('opennlp_output.txt', 'r') as f:\n",
    "        return extractLan(f,n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_en = run_opennlp(df_en)\n",
    "re_fr = run_opennlp(df_fr)\n",
    "re_de = run_opennlp(df_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English, Spanish, German, Italian, French, Dutch, Romanian\n",
    "# {'en': 0, 'de': 1, 'es': 2, 'it': 3, 'fr': 4, 'nl': 5, 'ro': 6}\n",
    "# label = {'eng': 0, \"spa\": 2, \"deu\": 1, \"ita\": 3, \"fra\": 4, \"nld\": 5, \"ron\": 6, \"other\": 7}\n",
    "label = {'eng': 0, \"deu\": 1, \"fra\": 2,\"other\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_label(result):\n",
    "    for i in range(len(result)):\n",
    "        key = result[i]\n",
    "        if key in label:\n",
    "            result[i] = label[key]\n",
    "        else:\n",
    "            result[i] = 7\n",
    "\n",
    "replace_label(re_en)\n",
    "replace_label(re_de)\n",
    "replace_label(re_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df[\"lang\"].unique()\n",
    "\n",
    "label_dict = {\"en\":0,\"de\":1,\"fr\":2}\n",
    "\n",
    "\n",
    "df_en['lang'] = df_en.lang.replace(label_dict)\n",
    "df_de['lang'] = df_de.lang.replace(label_dict)\n",
    "df_fr['lang'] = df_fr.lang.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# languages\n",
    "# q3 ['en', 'de', 'es', 'it', 'fr', 'nl']\n",
    "# q4 ['en', 'de', 'es', 'it', 'fr', 'nl', 'ro']\n",
    "# q5 ['en', 'de', 'es', 'it', 'fr', 'nl', 'ro']\n",
    "# q6 ['en', 'fa', 'de', 'es', 'it', 'fr', 'nl', 'ro']\n",
    "# q7 ['en', 'de', 'it', 'fr']\n",
    "# q8 ['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN\n",
    "# q3 0.595\n",
    "# q4 0.72\n",
    "# q5 0.593\n",
    "# q6 0.59\n",
    "# q7 0.558\n",
    "# q8 0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FR\n",
    "# q3 0.545\n",
    "# q4 0.60\n",
    "# q5 0.566\n",
    "# q6 0.52\n",
    "# q7 0.65\n",
    "# q8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE\n",
    "# q3 0.656\n",
    "# q4 0.78\n",
    "# q5 0.673\n",
    "# q6 0.54\n",
    "# q7 0.62\n",
    "# q8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4634146341463415"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_en[\"lang\"], re_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oshara/Programs/anaconda2/envs/jupy/lib/python3.7/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/oshara/Programs/anaconda2/envs/jupy/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_fr[\"lang\"], re_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_de[\"lang\"], re_de)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
